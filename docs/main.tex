%review=doublespace preprint=single 5p=2 column
\documentclass[12pt,3p,authoryear]{elsarticle}

%% add packages %%
%% ------------ %%
\usepackage[hyphens]{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{caption}
\usepackage{subfig}
\usepackage{amssymb, amsmath}
\usepackage[inline]{enumitem}
\usepackage{float}
\usepackage{tabularx}
\usepackage[dvipsnames, table]{xcolor}
\usepackage{ifxetex, ifluatex}
\usepackage{fixltx2e}
\usepackage[unicode=true, colorlinks]{hyperref}
\usepackage{cleveref}
\usepackage{tabu}
\usepackage{mathpazo}
%% ------------ %%

%% Conditional Packages %%
%% -------------------- %%

\usepackage{easyReview}



% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}


\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}



    \setmonofont{sourcecodepro}


\fi

% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}






\usepackage{longtable}




% Pandoc toggle for numbering sections (defaults to be off)
\setcounter{secnumdepth}{5}

%% Use Landscape Pages
\usepackage{lscape}

\usepackage{setspace}
\setstretch{1.5}

\usepackage{lmodern}

%% -------------------- %%

%% Create and Provide some customizations %%
%% -------------------------------------- %%
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
  
%% Custom macros
\newtheorem{mydef}{Definition}
\newcommand{\bs}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\diag}[1]{\mathrm{diag}\left(#1\right)}
\newcommand{\seq}[3][1]{\ensuremath{#2_{#1},\ldots,\,#2_{#3}}}
\newcommand{\note}[1]{\marginpar{\scriptsize\tt{\color{RoyalBlue}#1}}}
\newcommand{\edit}[1]{{\color{OrangeRed} #1}}

%% Declare Operators
\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}

% set some lengths
\setlength{\parindent}{0pt}
% \setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines

%% Hyperref color setup
\AtBeginDocument{%
  %% Define Colors
  \newcommand\myshade{80}
  \colorlet{mylinkcolor}{violet!\myshade!black}
  \colorlet{mycitecolor}{YellowOrange!\myshade!black}
  \colorlet{myurlcolor}{Aquamarine!\myshade!black}

  \hypersetup{
    breaklinks = true,
    bookmarks  = true,
    pdfauthor  = {},
    pdftitle   = {Comparison of Multivariate Estimation Methods},
    linkcolor  = mylinkcolor,
    citecolor  = mycitecolor,
    urlcolor   = myurlcolor,
    colorlinks = true,
  }
}
\urlstyle{same}  % don't use monospace font for urls
%% -------------------------------------- %%

%% Customizations %%
%% -------------- %%
 % turn line numbering on

%% -------------- %%

%% Configure Bibliography %%
%% ---------------------- %%
\bibliographystyle{elsarticle-harv}
\biboptions{numbers,sort&compress}

\makeatletter
\providecommand{\doi}[1]{%
  \begingroup
    \let\bibinfo\@secondoftwo
    \urlstyle{rm}%
    \href{http://dx.doi.org/#1}{%
      doi:\discretionary{}{}{}%
      \nolinkurl{#1}%
    }%
  \endgroup
}
\makeatother

% 

%% Header Includes %%
%% --------------- %%
%% --------------- %%



\begin{document}
%% --- Front Matter Start --- %%
\begin{frontmatter}

  \title{Comparison of Multivariate Estimation Methods}
  
    \author[KBM]{Raju Rimal\corref{c1}}
   \ead{raju.rimal@nmbu.no} 
   \cortext[c1]{Corresponding Author}
    \author[KBM]{Trygve Almøy}
   \ead{trygve.almoy@nmbu.no} 
  
    \author[NMBU]{Solve Sæbø}
   \ead{solve.sabo@nmbu.no} 
  
      \address[KBM]{Faculty of Chemistry and Bioinformatics, Norwegian University of Life
Sciences, Ås, Norway}
    \address[NMBU]{Prorector, Norwegian University of Life Sciences, Ås, Norway}
  
  \begin{abstract}
  Prediction performance often does not reflect the estimation behaviour
  of a method. High error in estimation not necessarily results in high
  prediction error but can lead to an unreliable prediction when test data
  are in a different direction than the training data. In addition, the
  effect of a variable becomes unstable and can not be interpreted in such
  situations. Many research fields are more interested in these estimates
  than performing prediction. This study compares some newly-developed
  (envelope) and well-established (PLS, PCR) prediction methods using
  simulated data with specifically designed properties such as
  multicollinearity, the correlation between multiple responses and
  position of principal components of predictor that are relevant for the
  response. This study aims to give some insight into these methods and
  help the researcher to understand and use them for further study.
  \emph{Write some specifics from the results to show what we have found.}
  \end{abstract}
   \begin{keyword} model-comparison,multi-response,simrel,estimation,estimation error,meta modeling\end{keyword}

\end{frontmatter}

\section{Introduction}\label{introduction}

Estimation of parameters in a regression model is an integral part of
many research study. Research fields such as social science,
econometrics, psychology and medical study are more interested in
measuring the impact of certain indicator or variable rather than
performing prediction. Such studies have a large influence on people's
perception and also help in policy making and decisions.

Technology has facilitated researcher to collect a large amount of data
however often times, such data either contains irrelevant information or
are highly collinear. Researchers are devising new estimators to extract
information and identify their inter-relationship. Some estimators are
robust towards fixing the multicollinearity problem while some are
targeted to model only the relevant information contained in the
response variable.

This study extends the \citep{rimal2019pred} and compares some
well-established estimators such as Principal Components Analysis (PCA),
Partial Least Squares (PLS) together with two new methods based on
envelope estimation: Envelope estimation in predictor space (Xenv)
\citep{cook2010envelope} and simultaneous estimation of envelope (Senv)
\citep{cook2015simultaneous}. The estimation process of these methods is
discussed in {[}Methods{]} section. The comparison tests the estimation
performance of these methods using multi-response simulated data from a
linear model with controlled properties. The properties include the
number of predictors, level of multicollinearity, the correlation
between different response variables and the position of relevant
predictor components. These properties are explained in
\protect\hyperlink{experimental-design}{Experimental Design} section
together with the strategy behind the simulation and data model.

\section{Simulation Model}\label{simulation-model}

\begin{itemize}
\tightlist
\item
  Reduction of the regression model
\item
  Include the figure from previous paper
\item
  How the covariance and coefficients are related
\item
  From the construction of the covariance matrix of latent variables to
  the simulated data
\item
  How and what simulation parameters are related to properties of data
\end{itemize}

\section{Estimation Methods}\label{estimation-methods}

A regression model is written as,

\begin{equation}
\underset{(1\times m)}{\mathbf{y}} =
  \underset{(1\times p)(p\times m)}
    {\mathbf{x}\boldsymbol{\beta}} +
  \underset{(1 \times m)}{\boldsymbol{\varepsilon}}
\label{eq:reg-model}
\end{equation}

where \(\mathbf{y}\) is a vector of \(m\) responses measured about their
means, \(\mathbf{x}\) is a vector of \(p\) predictors measured about
their means, \(\boldsymbol{\beta}\) is a matrix of regression
coefficients and \(\boldsymbol{\varepsilon}\) is a vector of independent
error terms with constant variance \(\boldsymbol{\Sigma}_{y|x}\). In
ordinary least squares, coefficient \(\boldsymbol{\beta}\) is estimated
as,

\begin{equation}
\underset{(p\times m)}{\boldsymbol{\hat{\beta}}} =
  \left(\underset{(p\times n)}{\mathbf{x}^t}
  \underset{(n\times p)}{\mathbf{x}}\right)^{-1}
  \underset{(p \times n)(n \times m)}{\mathbf{x}^t\mathbf{y}}
\label{eq:reg-beta}
\end{equation}

\subsection{Principal Components
Regression}\label{principal-components-regression}

Principal Components are new set of variables from the transformation of
original dataset such that they are uncorrelated with each other and the
variation in the original data are ordered from first to last of these
new variables. Let us define a transformation of \(\mathbf{x}\) as,

\begin{equation}
\underset{(1\times p)}{\mathbf{x}} =
  \underset{(1 \times k)}{\mathbf{z}}
  \underset{(k \times p)}{\mathbf{R}^t}
\label{eq:x2z}
\end{equation}

where \(\mathbf{R}\) is the eigenvectors corresponding to the covariance
of \(\mathbf{x}\) and \(\mathbf{z}\) are the principal components. A
regression model can be defined in terms of \(\mathbf{z}\) as,

\begin{equation}
\underset{(1 \times m)}{\mathbf{y}} =
  \underset{(1 \times k)}{\mathbf{z}}
    \underset{(k \times m)}{\boldsymbol{\alpha}} +
  \underset{(1 \times m)}{\boldsymbol{\varepsilon}}
\label{eq:latent-model}
\end{equation}

Since the variation is ordered in \(z\), only \(k\le p\) columns of
\(z\) are used so that \(p-k\) uninformative components are not used for
modeling. The regression coefficient of \eqref{eq:latent-model} can be
estimated as,

\begin{equation}
\underset{(k\times m)}{\boldsymbol{\hat{\alpha}}} =
  \left(\underset{(k \times n)}{\mathbf{z}^t}
    \underset{(n \times k)}{\mathbf{z}}\right)^{-1}
  \underset{(k \times n)(n \times m)}{\mathbf{z}^t\mathbf{y}}
\label{eq:reg-alpha}
\end{equation}

Using \eqref{eq:x2z} in \eqref{eq:reg-beta}, we get,

\[
\begin{aligned}
\underset{(p\times m)}{\boldsymbol{\hat{\beta}}} =
  \left[
    \underset{(p\times k)(k \times n)}{\mathbf{R}\mathbf{z}^t}
    \underset{(n\times k)(k \times p)}{\mathbf{z} \mathbf{R}^t}
  \right]^{-1}
  \underset{(p\times k)(k \times n)}{\mathbf{R}\mathbf{z}^t}
  \underset{(n\times m)}{y}
\end{aligned}
\]

\subsection{Partial Least Squares
Regression}\label{partial-least-squares-regression}

\begin{itemize}
\tightlist
\item
  How beta coefficients are constructed
\item
  How it is dependent on the variance-covariance matrices
\item
  In what way PLS1 and PLS2 differ
\end{itemize}

\subsection{Envelope Estimations}\label{envelope-estimations}

\begin{itemize}
\tightlist
\item
  How beta coefficients are constructed
\item
  How it is dependent on the variance-covariance matrices
\item
  In what way Xenv and Senv differ
\end{itemize}

\hypertarget{experimental-design}{\section{Experimental
Design}\label{experimental-design}}

An R \citep{coreR2018} package \texttt{simrel}
\citep{Rimal2018, saebo2015simrel} is used to simulate data. For the
simulation the number of observation is kept fixed at \(n = 100\) and
following four simulation parameters are used to obtain the data with
wide range of properties.

\begin{description}
\tightlist
\item[\textbf{Number of predictors:}]
In order to cover both tall \((n>p)\) and wide \((p>n)\) cases, \(p=20\)
and \(p=250\) number of predictors are simulated.
\item[\textbf{Multicollinearity in predictor variables:}]
A parameter \texttt{gamma} \((\gamma)\) in simulation controls the
exponential decline of eigenvalues \((\lambda_i, i = 1, \ldots p)\)
corresponding to predictor variables as,

\begin{equation}
  \lambda_i = e^{-\gamma(i-1)}, \gamma > 0 \text{ and } i = 1, 2, \ldots p
  \label{eq:gamma}
  \end{equation}

Two levels 0.2 and 0.8 of \texttt{gamma} are used for simulation so that
level 0.2 simulates the data with low multicollinearity and 0.8
simulates the data with high multicollinearity.
\item[\textbf{Position of relevant components:}]
Initial principal components of a non-singular covariance matrix are
larger than the later one. If the principal components corresponding to
predictors with larger variation is not relevant for a response, this
will just increase noise in the model. Here we will use two different
levels of position index of predictor components: a) 1, 2, 3, 4 and b)
5, 6, 7, 8. Predictor components irrelevant for a response makes
prediction difficult \citep{Helland1994b}. When combined with
multicollinearity, this factor can create both easy and difficult model
for both estimation and prediction.
\end{description}

\begin{figure}
\includegraphics[width=1\linewidth]{main_files/figure-latex/design-plot-1} \caption{Experimental Design of simulation parameters. Each point represents an unique data property.}\label{fig:design-plot}
\end{figure}

\begin{itemize}
\tightlist
\item
  Discuss the design
\item
  Include the design plot from previous paper
\item
  What nature of data properties is captured by the design and how
  diverse is it
\item
  What is the limitation
\item
  Discuss about the single latent component of response space
\end{itemize}

\subsection{Basis of Comparison}\label{basis-of-comparison}

\begin{itemize}
\tightlist
\item
  Similar to previous paper but for estimation error
\item
  Here we will also compare the estimated and true regression
  coefficient for each additional component
\item
  We can do this through graph
\item
  Is there some way we can do this through statistics
\end{itemize}

\section{Exploration}\label{exploration}

\begin{itemize}
\tightlist
\item
  A similar exploration as previous paper but can be different in case
  of new idea
\end{itemize}

\subsection{Dataset for Analysis}\label{dataset-for-analysis}

\begin{itemize}
\tightlist
\item
  Preparation of dataset for MANOVA analysis (i.e.~minimum estimation
  error using arbitrary number of components)
\item
  A component dataset is also created for testing the use of components
  by each of these methods
\end{itemize}

\subsection{Regression Coefficients}\label{regression-coefficients}

\begin{itemize}
\tightlist
\item
  In case of some idea on comparing regression coefficients through some
  statistical way, this can be included here
\item
  Otherwise can also be done just by using plots
\end{itemize}

\subsection{Prediction and Estimation
Error}\label{prediction-and-estimation-error}

\begin{itemize}
\tightlist
\item
  Explore both estimation error and number of components and try to bind
  them with the prediction error for the similar case
\end{itemize}

\section{Analysis}\label{analysis}

\begin{itemize}
\tightlist
\item
  A MANOVA model is fitted using the dataset prepared in previous
  section
\end{itemize}

\subsection{Error Analysis}\label{error-analysis}

\begin{itemize}
\tightlist
\item
  Effect analysis of estimation error model
\item
  Tie up these results with prediction error in previous paper
\end{itemize}

\subsection{Component Analysis}\label{component-analysis}

\begin{itemize}
\tightlist
\item
  Effect analysis of number of component model
\item
  Tie up these results in previous paper
\end{itemize}

\section{Discussion and Conclusion}\label{discussion-and-conclusion}

\begin{itemize}
\tightlist
\item
  A similar discussion but based more on why the methods worked in the
  way we have seen in the results in previous sections
\item
  Some concluding remarks and limitations (or a gate for further
  exploration)
\end{itemize}


\renewcommand\refname{References}
\bibliography{ref-db.bib}


\end{document}
