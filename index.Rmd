---
site: bookdown::bookdown_site
title: 'Comparison of Multivariate Estimation Methods'
date: "`r Sys.Date()`"
author:
  - name: Raju Rimal
    email: raju.rimal@nmbu.no
    affiliation: KBM
    footnote: Corresponding Author
  - name: Trygve Almøy
    email: trygve.almoy@nmbu.no
    affiliation: KBM
  - name: Solve Sæbø
    email: solve.sabo@nmbu.no
    affiliation: NMBU
address:
  - code: KBM
    address: Faculty of Chemistry and Bioinformatics, Norwegian University of Life Sciences, Ås, Norway
  - code: NMBU
    address: Prorector, Norwegian University of Life Sciences, Ås, Norway
classoption: ["12pt", "3p", "authoryear"]
monofont: 'sourcecodepro'
monofontoptions: "Scale=0.7"
colorlinks: true
linespacing: 1.5
fontfamily: mathpazo
use-landscape-page: yes
tables: yes
bibliography: ref-db.bib
biblio-title: References
biblio-style: elsarticle-harv
link-citations: true
github-repo: therimalaya/04-estimation-comparison
always_allow_html: true
url: 'http\://therimalaya.github.io/04-estimation-comparison'
knit: 'bookdown::render_book'
review: yes
keywords: ['model-comparison ', 'multi-response ', 'simrel ']
abstract: |
  Prediction performance often does not reflect the estimation behaviour of a method. High error in estimation not necessarily results in high prediction error but can leads to an unreliable prediction when test data are in a different direction than the training data. In addition, the effect of a variable becomes unstable and can not be interpreted in such situations. >> Fix from here << Here we have extend the previous study on prediction comparison to compare the estimation of the methods used in the study.

  While Data science is battling to extract information from the enormous explosion of data, many estimators and algorithms are being developed for better prediction. Researchers and data scientists often introduce new methods and evaluate them based on various aspects of data. However, studies on the impact of/on model with multiple response model is limited. This study compares some newly-developed (envelope) and well-established (PLS, PCR) prediction methods based on simulated data specifically designed by varying properties such as multicollinearity, correlation between multiple responses and amount of information content in predictor variables. This study aims to give some insight on these methods and help researcher to understand and use them for further study.
---

```{r, echo = FALSE, warning=FALSE, message=FALSE, cache=FALSE}
options(digits = 3, scipen = 999)
source("scripts/00-function.r")
source("scripts/01-setup.r")
knitr::opts_chunk$set(comment = NULL, out.width = "100%", echo = FALSE)
if (knitr::is_html_output()) {
  knitr::opts_chunk$set(dev = 'svg', fig.retina = 2, dev.args = list(family="mono"))
}
```


```{r, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}
source("scripts/03-collection.r")
```


# Introduction #

Estimation of parameters in a regression model is an integral part in many research study. Research fields such as social science, econometric, psychology and medical study are more interested in measuring the impact of certain indicator or variable rather than performing prediction. Such studies has large influence in people's perception and also help in policy making and decisions.

This study extends the [Refer to my current paper] and compares some well established estimators such as Principal Components Analysis (PCA), Partial Least Squares (PLS) together with two new methods based on envelope estimation: Envelope estimation in predictor space (Xenv) and simultaneous estimation of envelope (Senv). The comparison tests the estimation performance of these methods using simulated data with controlled properties. The properties includes the number of predictors, level of multicollinearity, correlation between different response variables and the position of relevant predictor components.

Prediction has been an essential components of modern data science, weather it is statistical analysis or machine learning. Modern technology has facilitated a massive explosion of data, however, such data often contain irrelevant information consequently making prediction difficult. Researchers are devising new methods and algorithms in order to extract information to create robust predictive models. Mostly such models contain predictor variables that are directly or indirectly correlated with other predictor variables. In addition studies often constitute of many response variables correlated with each other. These interlinked relationships influence any study, whether it is predictive modeling or inference.

Modern inter-disciplinary research fields such as chemometrics, econometrics and bioinformatics are handling multi-response models extensively. This paper attempts to compare some multivariate prediction methods based on their prediction performance on linear model data with specific properties. The properties includes correlation between response variables, correlation between predictor variables, number of predictor variables and the position of relevant predictor components. These properties are discussed more in the [Experimental Design] section. @saebo2015simrel and @Alm_y_1996 have made a similar comparison in the single response setting. In addition, @Rimal2018 has also made a basic comparison on some prediction methods and their interaction with the data properties of a multi-response model. The main aim of this paper is to present a comprehensive comparison of contemporary prediction methods such as simultaneous envelope estimation (Senv) [@cook2015simultaneous] and envelope estimation in predictor space (Xenv) [@cook2010envelope] with customary prediction methods such as Principal Component Regression (PCR), Partial Least Squares Regression (PLS) using simulated dataset with controlled properties. An experimental design and the methods under comparison are discussed further, followed by a brief discussion of the strategy behind the data simulation.


```{r scratch, echo = FALSE}
num_vec <- c('one', 'two', 'three', 'four', 'five', 
             'six', 'seven', 'eight', 'nine', 'ten')
names(num_vec) <- 1:10
```

