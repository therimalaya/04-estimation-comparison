# Experimental Design #
An R [@coreR2018] package `simrel` [@Rimal2018; @saebo2015simrel] is used to simulate the data for comparison. In the simulation, the number of observation is fixed at $n = 100$ and following four simulation parameters are used to obtain the data with a wide range of properties.

**Number of predictors: (`p`)**
: In order to cover both tall $(n>p)$ and wide $(p>n)$ cases, $p= `r opts$p[1]`$ and $p= `r opts$p[2]`$ number of predictors are simulated.

**Multicollinearity in predictor variables: (`gamma`)**
: A parameter `gamma` $(\gamma)$ in simulation controls the exponential decline of eigenvalues $(\lambda_i, i = 1, \ldots p)$ corresponding to predictor variables as,
  \begin{equation}
  \lambda_i = e^{-\gamma(i-1)}, \gamma > 0 \text{ and } i = 1, 2, \ldots p
  (\#eq:gamma)
  \end{equation}
: Two levels `r catvec(opts$gamma)` of `gamma` are used for simulation so that level `r opts$gamma[1]` simulates the data with low multicollinearity and `r opts$gamma[2]` simulates the data with high multicollinearity.

**Position of relevant components: (`relpos`)**
: Initial principal components of a non-singular covariance matrix are larger than the later one. If the principal components corresponding to predictors with larger variation is not relevant for a response, this will just increase the noise in the data. Here we will use two different levels of position index of predictor components (`relpos`): a) `r opts$relpos[1]` and b)  `r opts$relpos[2]`. Predictor components irrelevant for a response makes prediction difficult [@Helland1994b]. When combined with multicollinearity, this factor can create both an easy and difficult model for both estimation and prediction.

**Correlation in response variables: (`eta`)**
: Many estimators also uses the structure of response for their estimation. Here the correlation between the responses are varied through a simulation parameter `eta` $(\eta)$. The parameter controls the exponential decline of eigenvalues $\kappa_j, j = 1, \ldots m (\text{ number of responses})$ corresponding to response variables as,
\begin{equation}
\eta_j = e^{-\kappa(j-1)}, \kappa > 0 \text{ and } j = 1, 2, \ldots m
(\#eq:eta)
\end{equation}
: Four levels  `r catvec(opts$eta)` of `eta` are used in the so that level `r opts$eta[1]` simulates the data with uncorrelated response variables while `r opts$eta[length(opts$eta)]` simulates the highly correlated response variables.

```{r design-plot, fig.cap="Experimental Design of simulation parameters. Each point represents an unique data property.", echo = FALSE, fig.asp=0.4, fig.width=8}
design_chr %>%
    mutate(Design = row_number()) %>%
    ggplot(aes(eta, gamma)) +
    geom_point(shape=4) +
    ggrepel::geom_text_repel(
      aes(label = Design),
      nudge_x = 0.03, family = 'mono', fontface = "bold") +
    facet_grid(p ~ relpos, labeller=label_both) +
  scale_y_reverse(breaks = opts$gamma) +
    scale_x_continuous(breaks = opts$eta) +
    theme_minimal(base_size = 16, base_family = "mono") +
    theme(panel.grid.minor = element_blank(), text = element_text(face = "bold")) +
    coord_fixed(ratio=0.5)
```

Here we have assumed that there is only one informative response component. In the final dataset, all predictors together span the same space as the relevant predictor components and all response together span the same space as the one informative response component. In addition, the coefficient of determination is fixed at `r unique(opts$R2)` for all dataset.

A complete factorial design is adopted using different levels of factors discussed above to create 32 design (Figure \@ref(fig:design-plot)) each of which gives dataset with unique properties. From each of these design and each estimation method, 50 different datasets are simulated so that each of them has the same true population structure. In total, $`r length(mthds)` \times `r nrow(design)` \times 50$ i.e., `r length(mthds) * nrow(design) * 50` datasets are simulated.

(ref:cov-plot) Covariance between predictor components and response variables in the population (top) and in the simulated data (bottom) for four different designs. The Bar in the background represents the variance of the corresponding components.

```{r cov-plot, fig.pos = "H", fig.asp=0.6, fig.cap="(ref:cov-plot)", fig.width=8}
selected_designs <- design %>%
  mutate(Design = row_number()) %>%
  filter(p == 20, eta == 0)
sobj_list <- lapply(1:nrow(selected_designs), function(i){
  set.seed(2019)
  selected_designs %>% select(-Design) %>% get_design(i) %>% simulate()
})
names(sobj_list) <- paste0("Design", selected_designs$Design)
sigma_zy_pop <- map_df(sobj_list, function(obj){
  obj %>%
    cov_mat(which = "zy", use_population = TRUE) %>%
    tidy_sigma() %>%
    abs_sigma()
}, .id = "Design")
sigma_zy_samp <- map_df(sobj_list, function(obj){
  obj %>%
    cov_mat(which = "zy", use_population = FALSE) %>%
    tidy_sigma() %>%
    abs_sigma()
}, .id = "Design")
sigma_zy <- bind_rows(
  Population = sigma_zy_pop,
  Sample = sigma_zy_samp,
  .id = "Type"
)
lambda_df <- bind_rows(
  Population = map_df(sobj_list, tidy_lambda, use_population = TRUE, .id = "Design"),
  Sample = map_df(sobj_list, tidy_lambda, use_population = FALSE, .id = "Design"),
  .id = "Type"
)
design_chr_selected <- selected_designs %>%
    select(relpos, gamma, Design) %>%
    modify_at("relpos", paste0) %>%
    mutate_at("relpos", ~gsub("list\\(c\\((.+)\\))", "\\1", ..1))
design_name <- paste0("Design", selected_designs$Design)
design_lbl <- with(design_chr_selected, {
  paste(design_name,
        map2_chr(
          paste0("relpos:", relpos), paste0("gamma:", gamma),
          paste, sep = " | "),
        sep = "\n")
})
names(design_lbl) <- design_name
ggplot(sigma_zy, aes(Predictor, Covariance, color = factor(Response))) +
  geom_bar(data = lambda_df, aes(x = Predictor, y = lambda),
           fill = "lightgrey",
           stat = "identity", inherit.aes = FALSE) +
  geom_point(size = rel(0.8)) +
  geom_line(size = rel(0.5)) +
  facet_grid(cols = vars(Design), rows = vars(Type),
             labeller = labeller(Design = design_lbl )) +
  theme(legend.position = "bottom") +
  labs(x = "Components",
       y = "Absolute Covariances",
       color = "Response Variable",
       title = "Covariance between Predictor Components and Responses",
       subtitle = "High/Low Multicollinearity with near/far relevant predictors") +
  scale_color_brewer(palette = "Set1")
```

The simulation properties are directly reflected in the simulated data. For example, in Figure \@ref(fig:cov-plot), design pairs `r catvec(subset(design_chr_selected, gamma == 0.2, select = "Design", drop = TRUE))` as well as `r catvec(subset(design_chr_selected, gamma == 0.9, select = "Design", drop = TRUE))` differs their properties only in terms of relevant predictor components while the design pairs `r catvec(subset(design_chr_selected, relpos == "1, 2, 3, 4", select = "Design", drop = TRUE))` as well as `r catvec(subset(design_chr_selected, relpos == "5, 6, 7, 8", select = "Design", drop = TRUE))` differs only in-terms of level of multicollinearity. The properties in population are also reflected in the simulated samples. The combination of these factor levels creates datasets that are easy or difficult for them to model.

```{r data-prep}
est_dta <- design_chr %>%
  select_if(function(x) n_distinct(x) > 1) %>%
  mutate(Design = as.character(1:n())) %>%
  mutate_at(vars(p, gamma, relpos, eta), as.factor) %>%
  right_join(est_error, by = "Design") %>%
  mutate_if(is.character, as.factor) %>%
  mutate_at("p", as.factor) %>%
  mutate(Response = paste0("Y", Response))
est_spread_df <- est_dta %>%
  as.data.frame() %>%
  select(-Design, -q) %>%
  spread(Response, Est_Error)
min_comp_stk <- est_dta %>%
  group_by(p, relpos, eta, gamma, Method, Tuning_Param, Response) %>%
  summarize(Est_Error = mean(Est_Error)) %>%
  group_by(p, relpos, eta, gamma, Method, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Est_Error)])
est_min <- est_dta %>%
  select(-Design, -q) %>%
  semi_join(min_comp_stk, by = c(
    "p", "relpos", "eta", "gamma", "Method",
    "Tuning_Param", "Response"
  )) %>% select(-Tuning_Param) %>%
  spread(Response, Est_Error)
comp_min <- est_dta %>%
  group_by(p, relpos, eta, gamma, Method, Replication, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Est_Error)]) %>%
  spread(Response, Tuning_Param)
```


# Basis of Comparison

The focus of this study is to extend the exploration of @rimal2019pred to compare the estimation performance of PCR, PLS1, PLS2, Xenv and Senv methods. The performance is measured on the basis of,

a) average estimation error computed as in \@ref(eq:estimated-est-error)
b) the average number of components used by the methods to give minimum estimation error

Let us define the expected estimation error as
\begin{equation}
  \text{MSE}\left(
    \boldsymbol{\hat{\beta}}_{ijkl}
  \right) =
  \mathsf{E}{\left[
    \frac{1}{\sigma_{y_j}^2}\left(
      \boldsymbol{\beta}_{ij} - \boldsymbol{\hat{\beta}_{ijkl}}
    \right)^t
    \left(
      \boldsymbol{\beta}_{ij} - \boldsymbol{\hat{\beta}_{ijkl}}
    \right)
  \right]}
(\#eq:est-error)
\end{equation}
for response $j = 1, \ldots 4$ in a given design $i=1, 2, \ldots 32$ and method $k=1(PCR), \ldots 5(Senv)$ using $l=0, \ldots 10$ number of components. Here $\sigma_{y_j}^2$ is the variance of response $j$. Since both the expectation and the variance of $\hat{\boldsymbol{\beta}}$ are unknown, the estimation error are estimated using data from 50 replications as follows,

\begin{equation}
\widehat{\text{MSE}\left(\hat{\beta}\right)_{ijkl}} =
  \frac{1}{50}\sum_{r=1}^{50}{\left[
    \widehat{\text{MSE}_\circ\left(\hat{\beta}\right)_{ijkl}}  
  \right]}
(\#eq:estimated-est-error)
\end{equation}
where, $\widehat{\text{MSE}\left(\hat{\beta}\right)_{ijkl}}$ is the estimated prediction error averaged over $r=50$ replicates and, $$\text{MSE}_\circ\left(\boldsymbol{\hat{\beta}}\right)_{ijklr} = \frac{1}{\sigma_{y_j}^2}\left[\left(\boldsymbol{\beta}_{ij} -\boldsymbol{\hat{\beta}_{ijklr}}\right)^t\left(\boldsymbol{\beta}_{ij} - \boldsymbol{\hat{\beta}_{ijklr}}\right)
  \right]$$

Our further discussion revolves around _Error Dataset_ and _Component Dataset_ as in the prediction comparison paper @rimal2019pred. For a given estimation method, design, and response, the component that gives the minimum of estimation error averaged over all replicates is selected as, 
\begin{equation}
  l_\circ = \operatorname*{argmin}_{l}\left[\frac{1}{50}\sum_{r=1}^{50}{\widehat{\text{MSE}_\circ\left(\hat{\beta}\right)}_{r}}\right]
  (\#eq:min-err)
\end{equation}
The estimation error $\widehat{\text{MSE}_\circ\left(\hat{\beta}\right)}$ for every methods, design and response corresponding to $l_\circ$ component, computed as
\@ref(eq:min-err), is then regarded as _error dataset_ in the subsequent
analysis. Let $\mathbf{u}_{8000\times4}=(u_j)$ where $u_j$ is the $j^\text{th}$ column of $\mathbf{u}$ denoting the estimation error corresponding to response $j=1, \ldots 4$ in the context of this dataset. Further, let the number of components that
result in minimum estimation error in each replication be $l_\circ$ computed as
\@ref(eq:min-comp) will be considred as _component dataset_. Let
$\mathbf{v}_{8000\times4}=(v_j)$ where $v_j$ is the $j^\text{th}$ column of $\mathbf{v}$ denoting the outcome variable measuring the number of components used to obtain minimum estimation error corresponding to response $j=1, \ldots 4$.

\begin{equation}
  l_{\circ} = \operatorname*{argmin}_{l}\left[\widehat{\text{MSE}_\circ\left(\hat{\beta}\right)}\right]
  (\#eq:min-comp)
\end{equation}
