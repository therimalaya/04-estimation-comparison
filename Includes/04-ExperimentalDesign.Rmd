# Experimental Design #

An R [@coreR2018] package `simrel` [@Rimal2018; @saebo2015simrel] is used to simulate the data for comparison. In the simulation, number of response variables $m = 4$ and number of observations $n = 100$ are fixed, and the following four simulation parameters are varied to obtain data with a wide range of properties.

**Number of predictors: (`p`)**
: In order to cover both tall $(n>p)$ and wide $(p>n)$ cases, $p= `r opts$p[1]`$ and $p= `r opts$p[2]`$ number of predictors are simulated.

**Multicollinearity in predictor variables: (`gamma`)**
: A parameter `gamma` $(\gamma)$ controls the exponential decline of eigenvalues in $\boldsymbol{\Sigma_{xx}} (\lambda_i, i = 1, \ldots p)$ as,
  \begin{equation}
  \lambda_i = e^{-\gamma(i-1)}, \gamma > 0 \text{ and } i = 1, 2, \ldots p
  (\#eq:gamma)
  \end{equation}
: Two levels, `r catvec(opts$gamma)`, of `gamma` are used for simulation so that level `r opts$gamma[1]` simulates data with low multicollinearity and `r opts$gamma[2]` simulates the data with high multicollinearity in $\mathbf{x}$ respectively.

**Position of relevant components: (`relpos`)**
: Initial principal components of a non-singular covariance matrix have higher variance than the later ones. If the principal components corresponding to predictors with larger variation are not relevant for a response, this will just increase the noise level in the data. Here we will use two different levels of a position index of true predictor components (`relpos`): a) `r opts$relpos[1]` and b)  `r opts$relpos[2]`. Predictor components irrelevant for a response make prediction difficult [@Helland1994b]. When combined with multicollinearity, this factor can create both easy and difficult cases for both estimation and prediction.

**Correlation in response variables: (`eta`)**
: Some estimators also use the dependence structure of response for estimation. Here the correlation between the responses is varied through a simulation parameter `eta` $(\eta)$. The parameter controls the exponential decline of eigenvalues $\kappa_j, j = 1, \ldots m (\text{ number of responses})$ of $\boldsymbol{\Sigma_{yy}}$ as,
\begin{equation}
\kappa_j = e^{-\eta(j-1)}, \eta > 0 \text{ and } j = 1, 2, \ldots m
(\#eq:eta)
\end{equation}
: Four levels  `r catvec(opts$eta)` of `eta` are used in the simulations. Level $\eta=`r opts$eta[1]`$ gives data with uncorrelated response variables, while $\eta=`r opts$eta[length(opts$eta)]`$ gives highly correlated response variables.

```{r design-plot, fig.cap="Experimental Design of simulation parameters. Each point represents an unique data property.", echo = FALSE, fig.asp=0.4, fig.width=8}
design_chr %>%
    mutate(Design = row_number()) %>%
    ggplot(aes(eta, gamma)) +
    geom_point(shape=4) +
    ggrepel::geom_text_repel(
      aes(label = Design),
      nudge_x = 0.03, family = 'mono', fontface = "bold") +
    facet_grid(p ~ relpos, labeller=label_both) +
  scale_y_reverse(breaks = opts$gamma) +
    scale_x_continuous(breaks = opts$eta) +
    theme_minimal(base_size = 16, base_family = "mono") +
    theme(panel.grid.minor = element_blank(), text = element_text(face = "bold")) +
    coord_fixed(ratio=0.5)
```

Using these simulation parameters, a latent covariance matrix is constructed as in \ref{eq:latent-model}.
\begin{equation}
  \begin{bmatrix}
    \mathbf{w} \\ \mathbf{z}
  \end{bmatrix} 
  \sim \mathsf{N}
  \begin{pmatrix}
    \begin{bmatrix}
      \boldsymbol{\mu}_w \\
      \boldsymbol{\mu}_z \\
    \end{bmatrix}, &&
    \begin{bmatrix}
      \boldsymbol{\Sigma}_{ww} & \boldsymbol{\Sigma}_{wz} \\
      \boldsymbol{\Sigma}_{zw} & \boldsymbol{\Sigma}_{zz} 
    \end{bmatrix}
  \end{pmatrix}
  (\#eq:latent-model)
\end{equation}
For example, $\eta=1.2$ gives $\boldsymbol{\Sigma}_{ww}$ as a diagonal matrix with `r round(exp(-1.2 * (1:4 - 1)), 2)` in its diagonal. However for $\eta=0$, $\boldsymbol{\Sigma}_{ww}$ will be an identity matrix. A similar approach is used for covariance matrix $\boldsymbol{\Sigma}_{zz}$. In addition, when the true relevant components are at position 1, 2, 3, 4, the covariance matrix $\boldsymbol{\Sigma}_{wz}$ with dimension $m \times p$ will have $\sigma_{11}, \sigma_{12}, \sigma_{13}$ and $\sigma_{14}$ in its first four columns and the rest are filled with zeros. These $\sigma$ values are the links that defines the relationship between the latent components of predictors and the first response component. Two random orthogonal rotation matrices $\mathbf{R}$ and $\mathbf{Q}$ are used to rotate the latent covariance matrices in order to obtain the covariance matrices in \ref{eq:model-1}. @Rimal2018 have discussed the underlying mechanism in details.

Here we have assumed that there is only one informative response component. Hence the relevant space of the response matrix has dimension one. For the predictors, there are 4 true relevant components, so the relevant space for predictor matrix has 4 dimension. In addition, the coefficient of determination is fixed at `r unique(opts$R2)` for all datasets.

A complete factorial design is adopted using the different levels of factors discussed above to create 32 designs (Figure \@ref(fig:design-plot)), each of which gives datasets with unique properties. From each of these design and each estimation method, 50 different datasets are simulated so that each of them has the same true population structure. In total, $`r length(mthds)` \times `r nrow(design)` \times 50$ i.e., `r length(mthds) * nrow(design) * 50` datasets are simulated.

(ref:cov-plot) Covariance between predictor components and each response variable in the population (top), and in the simulated data (bottom) for four different designs. The bars in the background represent the variance of the corresponding components (eigenvalues).

```{r cov-plot, fig.pos = "H", fig.asp=0.6, fig.cap="(ref:cov-plot)", fig.width=8}
selected_designs <- design %>%
  mutate(Design = row_number()) %>%
  filter(p == 20, eta == 0)
sobj_list <- lapply(1:nrow(selected_designs), function(i){
  set.seed(2019)
  selected_designs %>% select(-Design) %>% get_design(i) %>% simulate()
})
names(sobj_list) <- paste0("Design", selected_designs$Design)
sigma_zy_pop <- map_df(sobj_list, function(obj){
  obj %>%
    cov_mat(which = "zy", use_population = TRUE) %>%
    tidy_sigma() %>%
    abs_sigma()
}, .id = "Design")
sigma_zy_samp <- map_df(sobj_list, function(obj){
  obj %>%
    cov_mat(which = "zy", use_population = FALSE) %>%
    tidy_sigma() %>%
    abs_sigma()
}, .id = "Design")
sigma_zy <- bind_rows(
  Population = sigma_zy_pop,
  Sample = sigma_zy_samp,
  .id = "Type"
)
lambda_df <- bind_rows(
  Population = map_df(sobj_list, tidy_lambda, use_population = TRUE, .id = "Design"),
  Sample = map_df(sobj_list, tidy_lambda, use_population = FALSE, .id = "Design"),
  .id = "Type"
)
design_chr_selected <- selected_designs %>%
    select(relpos, gamma, Design) %>%
    modify_at("relpos", paste0) %>%
    mutate_at("relpos", ~gsub("list\\(c\\((.+)\\))", "\\1", ..1))
design_name <- paste0("Design", selected_designs$Design)
design_lbl <- with(design_chr_selected, {
  paste(design_name,
        map2_chr(
          paste0("relpos:", relpos), paste0("gamma:", gamma),
          paste, sep = " | "),
        sep = "\n")
})
names(design_lbl) <- design_name
ggplot(sigma_zy, aes(Predictor, Covariance, color = factor(Response))) +
  geom_bar(data = lambda_df, aes(x = Predictor, y = lambda),
           fill = "lightgrey",
           stat = "identity", inherit.aes = FALSE) +
  geom_point(size = rel(0.8)) +
  geom_line(size = rel(0.5)) +
  facet_grid(cols = vars(Design), rows = vars(Type),
             labeller = labeller(Design = design_lbl )) +
  theme(legend.position = "bottom",
        plot.subtitle = element_text(family = "mono")) +
  labs(x = "Components",
       y = "Absolute Covariances",
       color = "Response Variable",
       title = "Covariance between Predictor Components and Responses",
       subtitle = paste0(
           "High (gamma: 0.9) and Low (gamma: 0.2) Multicollinearity with\n",
           "Near (relpos: 1, 2, 3, 4) and Far (relpos: 5, 6, 7, 8) relevant predictors")) +
  scale_color_brewer(palette = "Set1")
```

The simulation properties are directly reflected in the simulated data. For example, in Figure \@ref(fig:cov-plot), design pairs `r catvec(subset(design_chr_selected, gamma == 0.2, select = "Design", drop = TRUE))` as well as `r catvec(subset(design_chr_selected, gamma == 0.9, select = "Design", drop = TRUE))` differ in their properties only in terms of position of relevant predictor components, while the design pairs `r catvec(subset(design_chr_selected, relpos == "1, 2, 3, 4", select = "Design", drop = TRUE))` as well as `r catvec(subset(design_chr_selected, relpos == "5, 6, 7, 8", select = "Design", drop = TRUE))` differ only in-terms of the level of multicollinearity. The population properties are also reflected in the simulated samples (bottom row Figure \@ref(fig:cov-plot)). The combination of these factor levels creates datasets that are easy or difficult with regard to estimation and prediction. We observe from Figure \@ref(fig:cov-plot) that it may be difficult to infer the structure of the latent relevant space of $\mathbf{x}$ from the estimated principal components and their estimated covariances with the observed responses.

```{r data-prep}
est_dta <- design_chr %>%
  select_if(function(x) n_distinct(x) > 1) %>%
  mutate(Design = as.character(1:n())) %>%
  mutate_at(vars(p, gamma, relpos, eta), as.factor) %>%
  right_join(est_error, by = "Design") %>%
  mutate_if(is.character, as.factor) %>%
  mutate_at("p", as.factor) %>%
  mutate(Response = paste0("Y", Response))
est_spread_df <- est_dta %>%
  as.data.frame() %>%
  select(-Design, -q) %>%
  spread(Response, Est_Error)
min_comp_stk <- est_dta %>%
  group_by(p, relpos, eta, gamma, Method, Tuning_Param, Response) %>%
  summarize(Est_Error = mean(Est_Error)) %>%
  group_by(p, relpos, eta, gamma, Method, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Est_Error)])
est_min <- est_dta %>%
  select(-Design, -q) %>%
  semi_join(min_comp_stk, by = c(
    "p", "relpos", "eta", "gamma", "Method",
    "Tuning_Param", "Response"
  )) %>% select(-Tuning_Param) %>%
  spread(Response, Est_Error)
comp_min <- est_dta %>%
  group_by(p, relpos, eta, gamma, Method, Replication, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Est_Error)]) %>%
  spread(Response, Tuning_Param)
```

# Basis of Comparison

The focus of this study is to extend the exploration of @rimal2019pred to compare the estimation performance of PCR, PLS1, PLS2, Xenv and Senv methods. The performance is measured on the basis of,

a) average estimation error computed as in \@ref(eq:estimated-est-error)
b) the average number of components used by the methods to give minimum estimation error

Let us define the expected estimation error as
\begin{equation}
  \text{MSE}\left(
    \widehat{\boldsymbol{\beta}}
  \right)_{ijkl} =
  \mathsf{E}{\left[
    \frac{1}{\sigma_{y_j}^2}\left(
      \boldsymbol{\beta}_{ij} - \boldsymbol{\widehat{\beta}_{ijkl}}
    \right)^t
    \left(
      \boldsymbol{\beta}_{ij} - \boldsymbol{\widehat{\beta}_{ijkl}}
    \right)
  \right]}
(\#eq:est-error)
\end{equation}
for response $j = 1, \ldots 4$ in a given design $i=1, 2, \ldots 32$ and method $k=1(PCR), \ldots 5(Senv)$ using $l=0, \ldots 10$ number of components. Here $\sigma_{y_j}^2$ is the variance of response $j$. Since both the expectation and the variance of $\widehat{\boldsymbol{\beta}}$ are unknown, the estimation error is estimated using data from 50 replications as follows,

\begin{equation}
\widehat{\text{MSE}\left(\widehat{\boldsymbol{\beta}}\right)_{ijkl}} =
  \frac{1}{50}\sum_{r=1}^{50}{\left[
    \widehat{\text{MSE}_\circ\left(\widehat{\boldsymbol{\beta}}\right)_{ijklr}}  
  \right]}
(\#eq:estimated-est-error)
\end{equation}
where, $\widehat{\text{MSE}\left(\widehat{\boldsymbol{\beta}}\right)_{ijkl}}$ is the estimated prediction error averaged over $r=50$ replicates and,
$$\widehat{\text{MSE}_\circ\left(\boldsymbol{\widehat{\beta}}\right)_{ijklr}} = 
  \frac{1}{\sigma_{y_j}^2}\left[\left(\boldsymbol{\beta}_{ij} -\boldsymbol{\widehat{\beta}_{ijklr}}\right)^t\left(\boldsymbol{\beta}_{ij} - \boldsymbol{\widehat{\beta}_{ijklr}}\right)
\right]$$

Our further discussion revolves around what we will refer to as the _Error Dataset_ and the _Component Dataset,_ as in the prediction comparison paper @rimal2019pred. For a given estimation method, design, and response, the component that gives the minimum estimation error averaged over all replicates is selected as, 
\begin{equation}
  l_\circ = \operatorname*{argmin}_{l}\left[\frac{1}{50}\sum_{r=1}^{50}{\widehat{\text{MSE}_\circ\left(\widehat{\boldsymbol{\beta}}\right)}_{r}}\right]
  (\#eq:min-err)
\end{equation}
Here we have skipped further indices on $\boldsymbol{\widehat{\boldsymbol{\beta}}}$ for brevity. The estimation error $\widehat{\text{MSE}_\circ\left(\widehat{\boldsymbol{\beta}}\right)}$ for every method, design and response corresponding to component $l_\circ$, computed as \@ref(eq:min-err), is then regarded as the _error dataset_ in the subsequent analysis. Let $\mathbf{u}_{8000\times4}=(u_j)$, where $u_j$ is the $j^\text{th}$ column of $\mathbf{u}$ denoting the estimation error corresponding to response $j=1, \ldots 4$ in the context of this dataset. Further, let the number of components that
result in minimum estimation error in each replication and computed as \@ref(eq:min-comp), comprise the _component dataset_. Let $\mathbf{v}_{8000\times4}=(v_j)$ where $v_j$ is the $j^\text{th}$ column of $\mathbf{v}$ denoting the outcome variable measuring the number of components used to obtain minimum estimation error corresponding to response $j=1, \ldots 4$.

\begin{equation}
  l_{\circ} = \operatorname*{argmin}_{l}\left[\widehat{\text{MSE}_\circ\left(\widehat{\boldsymbol{\beta}}\right)}\right]
  (\#eq:min-comp)
\end{equation}
